{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4358689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 17:00:17.005570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb65e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'gesture/train'\n",
    "test_path = \"gesture/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96483cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24016 images belonging to 17 classes.\n",
      "Found 11216 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "\n",
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58dac2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0291b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(17,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5808fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2402/2402 [==============================] - 148s 61ms/step - loss: 0.1341 - accuracy: 0.9735 - val_loss: 0.1074 - val_accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "2402/2402 [==============================] - 122s 51ms/step - loss: 8.4249e-04 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "2402/2402 [==============================] - 120s 50ms/step - loss: 4.5607e-04 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9768 - lr: 5.0000e-04\n",
      "loss of 0.00048405007692053914; accuracy of 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadadeaulia/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# In[23]:\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n",
    "imgs, labels = next(train_batches) # For getting next batch of imgs...\n",
    "\n",
    "imgs, labels = next(test_batches) # For getting next batch of imgs...\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#model.save('best_model_dataflair.h5')\n",
    "model.save('model/data_huruf_abjad_17.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2f90f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
